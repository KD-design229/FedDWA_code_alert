# GPR-FedSense：基于多模态提示与双层个性化的探地雷达联邦学习架构 - 详细实验方案

## 1. 实验目的 (Objectives)
本实验旨在全面验证 **GPR-FedSense** 架构在探地雷达（GPR）图像分类任务中的有效性、鲁棒性及优越性。具体目标包括：
1.  **验证性能优势**：证明 GPR-FedSense 在 Non-IID（非独立同分布）数据环境下，相比于传统联邦学习方法（如 FedAvg）和单一模态模型（如 ResNet），具有更高的分类准确率。
2.  **验证双层个性化机制**：证明服务端动态邻域聚合（FedDWA）与客户端自适应聚合（ALA）相结合，能有效缓解全局模型噪声对本地个性化性能的负面影响。
3.  **验证多模态提示工程**：证明引入 GPR 领域特定的文本提示（Domain-Specific Prompts）能显著提升 CLIP 模型对 GPR 图像特征的理解能力。

---

## 2. 实验环境与设置 (Environment & Settings)

### 2.1 硬件与软件环境
*   **操作系统**: Linux (Ubuntu 20.04) / Windows 10+ (支持 WSL2)
*   **GPU**: NVIDIA RTX 3090 / A100 (显存 $\ge$ 24GB 推荐，最低 12GB)
*   **深度学习框架**: PyTorch 1.10+
*   **核心库**: `clip`, `timm`, `transformers`, `numpy`, `pandas`, `scikit-learn`

### 2.2 数据集描述 (Dataset)
*   **数据来源**: 自建/公开 GPR 图像数据集（包含 Loose, Crack, Void, Water Abnormality 等类别）。
*   **预处理**:
    *   尺寸统一: Resize 至 $224 \times 224$ (适配 CLIP/ViT 输入)。
    *   增强策略: RandomHorizontalFlip, RandomRotation, **CLAHE (限制对比度自适应直方图均衡化)**, RandomGamma (模拟不同地质介质的信号衰减)。
*   **数据划分**:
    *   **客户端数量 ($N$)**: 10 ~ 20 个客户端。
    *   **Non-IID 设置**: 采用 Dirichlet 分布 ($\alpha=0.1$ 或 $\alpha=0.5$) 模拟极端数据异构。这意味着某些客户端可能只拥有某几类缺陷的数据（例如 Client 1 只有 Crack，Client 2 只有 Void）。

---

## 3. 实验设计 (Experimental Design)

为了全方位评估模型，我们将实验分为三组：**基准对比 (Baselines)**、**消融实验 (Ablation Studies)** 和 **可视化分析 (Visualization)**。

### 3.1 第一组：基准对比实验 (Comparative Analysis)
**目的**：证明 GPR-FedSense 在整体性能上超越现有主流方法。

| 实验编号 | 方法名称 | 模型架构 | 聚合策略 | 说明 |
| :--- | :--- | :--- | :--- | :--- |
| **Exp-B1** | **FedAvg (CNN)** | ResNet-18/50 | FedAvg | 传统的联邦学习基准，使用纯视觉 CNN 模型。 |
| **Exp-B2** | **FedAvg (ViT)** | ViT-B/16 | FedAvg | 使用纯视觉 Transformer 模型，验证架构差异。 |
| **Exp-B3** | **FedProx** | ResNet-18 | FedProx | 针对 Non-IID 优化的经典 FL 方法，增加近端项约束。 |
| **Exp-B4** | **FedCLIP (Zero-shot)** | CLIP (ViT-B/32) | FedAvg | 直接使用预训练 CLIP 进行零样本分类，不进行微调，验证预训练知识。 |
| **Exp-Ours**| **GPR-FedSense** | **CLIP + Adapter** | **FedDWA + ALA** | **本文提出的完整架构。** |

### 3.2 第二组：消融实验 (Ablation Studies)
**目的**：拆解 GPR-FedSense 的各个模块，证明每个组件的独立贡献。

#### 3.2.1 架构模块消融 (Architecture Modules)
验证双层个性化机制的有效性。

| 实验编号 | 包含模块 | 描述 | 预期结果 |
| :--- | :--- | :--- | :--- |
| **Exp-A1** | Base (FedAvg + CLIP) | 仅使用 CLIP 模型配合普通 FedAvg，无个性化机制。 | 性能一般，受 Non-IID 影响大。 |
| **Exp-A2** | + FedDWA Only | 在服务端引入动态加权聚合，客户端无 ALA。 | 性能提升，收敛加快，但本地适应性稍弱。 |
| **Exp-A3** | + ALA Only | 服务端使用 FedAvg，客户端引入自适应聚合 (ALA)。 | 本地个性化增强，但全局聚合仍受噪声干扰。 |
| **Exp-A4** | **FedDWA + ALA (Ours)** | **双层防护机制同时启用。** | **性能最佳，鲁棒性最强。** |

#### 3.2.2 提示工程消融 (Prompt Engineering)
验证 GPR 特定提示词的有效性。

| 实验编号 | 提示策略 | 提示词示例 | 说明 |
| :--- | :--- | :--- | :--- |
| **Exp-P1** | Generic Prompts | "a photo of a {class}." | 通用图像分类提示。 |
| **Exp-P2** | **Domain-Specific Prompts** | "GPR image showing hyperbolic reflection of {class}..." | **本文构建的物理感知提示词库。** |
| **Exp-P3** | Learnable Prompts (CoOp) | [V]_1 [V]_2 ... [CLASS] | (可选) 使用可学习向量替代手工提示，作为进阶对比。 |

---

## 4. 详细执行步骤 (Execution Plan)

### 阶段一：数据准备与配置 (Data Preparation)
1.  **整理数据集**: 确保数据目录结构符合 `ImageFolder` 格式 (`root/class/image.png`)。
2.  **生成分布文件**: 运行脚本生成 Non-IID 分布索引文件 (如 `config_client_data_indices.json`)，确保所有对比实验使用**完全相同**的数据划分，保证公平性。
3.  **配置 Prompt**: 在 `MLModel.py` 中确认 `custom_gpr_prompts` 字典已完整定义所有类别的物理描述。

### 阶段二：运行基准实验 (Running Baselines)
*   **运行 Exp-B1 (ResNet)**:
    ```bash
    python main.py --dataset gpr_custom --model resnet18 --algorithm FedAvg --learning_rate 0.01 --num_global_iters 100
    ```
*   **运行 Exp-B4 (FedCLIP Zero-shot)**:
    *   设置 `local_epochs = 0` 或仅评估模式，记录初始 CLIP 模型在 GPR 数据上的表现。

### 阶段三：运行 GPR-FedSense (Running Ours)
*   **运行完整模型**:
    ```bash
    python main.py --dataset gpr_custom --model fedclip_adapter --algorithm FedDWA --enable_ala True --learning_rate 0.005 --num_global_iters 100 --batch_size 32
    ```
    *   *注：参数需根据实际代码调整，确保开启 ALA 和 FedDWA 开关。*

### 阶段四：运行消融实验 (Running Ablations)
1.  **关闭 ALA**: 在配置中设置 `enable_ala = False`，运行 Exp-A2。
2.  **关闭 FedDWA**: 将算法设为 `FedAvg` 但保留 ALA，运行 Exp-A3。
3.  **替换 Prompts**: 临时修改 `MLModel.py`，将 `custom_gpr_prompts` 替换为简单的 `f"a photo of a {label}"`，运行 Exp-P1。

---

## 5. 评价指标 (Metrics)

1.  **Top-1 Accuracy (全局/平均)**: 所有客户端测试集准确率的平均值。
2.  **Per-Class Accuracy**: 针对 "Crack", "Void" 等关键类别的识别准确率（关注长尾类别）。
3.  **Communication Rounds to Convergence**: 达到目标准确率（如 85%）所需的通信轮次，评估收敛速度。
4.  **Robustness (方差)**: 不同客户端之间准确率的方差，方差越小说明系统对异构数据的适应性越好。

---

## 6. 结果可视化 (Visualization)

实验结束后，需生成以下图表用于论文：

1.  **收敛曲线图 (Learning Curves)**:
    *   X轴：通信轮次 (Communication Rounds)
    *   Y轴：测试集准确率 (Test Accuracy)
    *   内容：绘制 FedAvg, FedProx, GPR-FedSense 的曲线，展示我们的方法“起点高、上升快、波动小”。

2.  **t-SNE 特征分布图**:
    *   提取训练好的模型（ResNet vs. GPR-FedSense）在测试集上的倒数第二层特征。
    *   使用 t-SNE 降维至 2D 平面。
    *   预期：GPR-FedSense 的特征点簇（Cluster）类间距离更大，类内更紧凑。

3.  **混淆矩阵 (Confusion Matrix)**:
    *   展示模型在易混淆类别（如不同类型的空洞或介质层）上的区分能力。

4.  **Grad-CAM 热力图 (可选)**:
    *   可视化模型关注的图像区域。证明使用了 "hyperbolic reflection" 提示后，模型确实聚焦在双曲线特征上。

---

## 7. 附录：推荐参数配置表 (Recommended Hyperparameters)

| 参数 | 推荐值 | 备注 |
| :--- | :--- | :--- |
| `num_clients` | 10 | 模拟中小型联邦网络 |
| `join_ratio` | 1.0 | 全员参与（或 0.5 随机参与） |
| `global_rounds` | 100 | 视收敛情况调整 |
| `local_epochs` | 5 | 本地训练轮数 |
| `batch_size` | 32 | 显存允许可设为 64 |
| `learning_rate` | 1e-3 (Adapter) / 1e-4 (Backbone) | Adapter 学习率通常大一些 |
| `optimizer` | AdamW | 配合 CosineAnnealing 调度器 |
| `alpha` (Dirichlet) | 0.1 | 强 Non-IID 设置 |

---
**执行建议**：请优先完成 **Exp-Ours** 和 **Exp-B1** 的对比，这是论文成立的基石。一旦这两个实验拉开差距，后续的消融实验只是锦上添花。